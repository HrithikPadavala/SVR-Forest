{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVoRF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2lxGsV6Njm6Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import pdb\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_curve, roc_auc_score, auc, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class node():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "class tree(node):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.leaf = True\n",
        "        self.class_label = None\n",
        "        self.standardize_para = None    \n",
        "        \n",
        "    @staticmethod\n",
        "    def Overlap_Rec(rec1, rec2):\n",
        "        upmat = rec1.copy()\n",
        "        upmat[:,0] = rec2[:,1]\n",
        "        lowmat = rec1.copy()\n",
        "        lowmat[:,1] = rec2[:,0]\n",
        "        rec = rec1.copy()\n",
        "        rec[:,0] = np.amax(lowmat, axis=1)\n",
        "        rec[:,1] = np.amin(upmat, axis=1)\n",
        "        return rec\n",
        "            \n",
        "    def surface_funs(self, rec, label, reclst0, labellst0, epsilon=10**(-12)):  \n",
        "        ''' Returns all the necessary parameters to compute the change of surface of the whole\n",
        "        tree once a new partition at rec is made. Currently only working for d>=3.\n",
        "        This function concerns all surfaces bordering and inside rec.\n",
        "        '''\n",
        "        ## Processing all overlapping cells \n",
        "        d = np.shape(rec)[0]\n",
        "        V = np.prod(rec[:,1] - rec[:,0])\n",
        "        S_faces = np.zeros(d)\n",
        "        overlap = np.zeros((d, 2))   ## the overlapping surface between rec and other rectangles that are labeled 1, at two faces of feature j\n",
        "        sub_overlap = [None]*d      ## sub_overlap is a list, with each element as [start, end, sub overlapping surface]\n",
        "        for j in range(d):\n",
        "            sub_overlap[j] = []\n",
        "            S_faces[j] = V / (rec[j,1] - rec[j,0])\n",
        "        S = np.sum(S_faces) * 2\n",
        "        ans = [None]*(d+1)\n",
        "        ## If reclst is empty:\n",
        "        if len(labellst0) == 0:\n",
        "            for j in range(d):\n",
        "                intercepts10 = [2*S_faces[j]]\n",
        "                slopes10 = [(S - S_faces[j]*2) / (rec[j,1] - rec[j,0])]\n",
        "                ans[j] = ([rec[j,0]], slopes10, intercepts10, S_faces[j])  \n",
        "            ans[d] = (0, S)\n",
        "            return ans\n",
        "            \n",
        "        for i in range(len(labellst0)):\n",
        "            if labellst0[i] == 0:\n",
        "                continue\n",
        "            recnow = reclst0[i]    \n",
        "            contact_feat = -1\n",
        "            for j in range(d):\n",
        "                if rec[j,0] == recnow[j,1]:\n",
        "                    contact_feat = j\n",
        "                    contact_direct = 0\n",
        "                    break\n",
        "                elif rec[j,1] == recnow[j,0]:\n",
        "                    contact_feat = j\n",
        "                    contact_direct = 1 \n",
        "                    break\n",
        "            if contact_feat == -1:\n",
        "                continue\n",
        "            overlap_rec = self.Overlap_Rec(rec, recnow)\n",
        "            overlap_rec_del = np.delete(overlap_rec, contact_feat, axis=0)\n",
        "            if np.min(overlap_rec_del[:,1]-overlap_rec_del[:,0]) <= 0:\n",
        "                continue\n",
        "            overlap_V = np.prod(overlap_rec_del[:,1] - overlap_rec_del[:,0])\n",
        "            overlap[contact_feat, contact_direct] += overlap_V\n",
        "            feats = np.delete(np.arange(d), contact_feat)\n",
        "            for j in feats:\n",
        "                sub_overlap[j].append([overlap_rec[j,0], overlap_rec[j,1], overlap_V/(overlap_rec[j,1]-overlap_rec[j,0])])               \n",
        "        \n",
        "        ## Compute piecewise linear functions with overlapping information\n",
        "        s_0 = np.sum(overlap)\n",
        "        s_1 = S - s_0\n",
        "        ans[d] = (s_0, s_1)\n",
        "        for j in range(d):\n",
        "            sub_overlap_j = sub_overlap[j]\n",
        "            if len(sub_overlap_j) == 0:\n",
        "                intercepts10 = [s_0 - overlap[j,0] + S_faces[j] - overlap[j,0] + S_faces[j]]\n",
        "                slopes10 = [(S - S_faces[j]*2) / (rec[j,1] - rec[j,0])]\n",
        "                ans[j] = ([rec[j,0]], slopes10, intercepts10, S_faces[j])   \n",
        "                continue\n",
        "            slopes_changes = np.zeros((2*len(sub_overlap_j),2))  ## both slopes_changes and slopes depicts slopes overlapping with elements of reclst with label 1\n",
        "            sidelen_j = rec[j,1] - rec[j,0]\n",
        "            for i in range(len(sub_overlap_j)):\n",
        "                slopes_changes[i+i,:] = [sub_overlap_j[i][0], sub_overlap_j[i][2]]\n",
        "                slopes_changes[i+i+1,:] = [sub_overlap_j[i][1], -sub_overlap_j[i][2]]\n",
        "            slopes_changes = slopes_changes[np.argsort(slopes_changes[:,0]),:]\n",
        "            checkpoints = []\n",
        "            slopes = []\n",
        "            value = rec[j,0]\n",
        "            slope_all = (S - S_faces[j]*2) / sidelen_j\n",
        "            sl = 0\n",
        "            for k in range(len(slopes_changes)): \n",
        "                if np.abs(slopes_changes[k,0]-value) < epsilon:\n",
        "                    sl += slopes_changes[k,1]\n",
        "                else:\n",
        "                    checkpoints.append(value)\n",
        "                    value = slopes_changes[k,0]\n",
        "                    slopes.append(sl)\n",
        "                    sl += slopes_changes[k,1]\n",
        "                    if np.abs(slopes_changes[k,0]-rec[j,1]) < epsilon:\n",
        "                        break\n",
        "            try:                \n",
        "                if len(checkpoints) == 0:\n",
        "                    intercepts10 = [s_0 - overlap[j,0] + S_faces[j] - overlap[j,0] + S_faces[j]]\n",
        "                    slopes10 = [(S - S_faces[j]*2) / (rec[j,1] - rec[j,0])]\n",
        "                    ans[j] = ([rec[j,0]], slopes10, intercepts10, S_faces[j])   \n",
        "                    continue\n",
        "                if np.abs(checkpoints[-1]-value) >= epsilon:\n",
        "                    checkpoints.append(value)\n",
        "                    slopes.append(sl)\n",
        "            except:\n",
        "                pdb.set_trace()\n",
        "                debug = checkpoints\n",
        "            slopes10 = slope_all - 2*np.array(slopes)\n",
        "            intercepts10 = np.zeros(len(checkpoints)) \n",
        "            intercepts10[0] = s_0 - overlap[j,0] + S_faces[j] - overlap[j,0] + S_faces[j]\n",
        "            for k in range(1,len(checkpoints)):\n",
        "                if checkpoints[k] < checkpoints[k-1]:\n",
        "                    print('Error: invalid checkpoints: '+str(checkpoints))\n",
        "                intercepts10[k] = intercepts10[k-1] + slopes10[k-1]*(checkpoints[k]-checkpoints[k-1])\n",
        "            ans[j] = (checkpoints, slopes10, intercepts10, S_faces[j])            \n",
        "        return ans            \n",
        "                \n",
        "    def fit_sv(self, X, Y, pen, c0=1, weight=1, border=None, standardize=False, \n",
        "               criterion='gini', min_split_weight=None, min_leaf_weight=None, tol=10**(-10), maximal_leaves=None):       \n",
        "        '''\n",
        "        Function to Fit a SVR-Tree.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: ndarray of shape n \\times d\n",
        "            Features of data\n",
        "        Y: ndarry or list of length n\n",
        "            Response variable of data\n",
        "        pen: float\n",
        "            Penalty parameter of surface-to-volume ratio. We suggest to try values in the\n",
        "            interval [0.001, 1]\\times n^{-1/3}.\n",
        "        c0: float\n",
        "            c0 parameter is feature selections. If feature_select=False, c0 does not have\n",
        "            any impacts on this function. Default value is 1.\n",
        "        weight: float\n",
        "            Weight for minority class samples. Should be no less than 1. Default value is 1.\n",
        "        border: ndarray of shape d \\times 2\n",
        "            A hyperrectangle where the features of data lie in. If not provided, the program \n",
        "            will automatically compute one. If \"border\" is provided, \"standardized\" must by True.\n",
        "        standardize: boolean\n",
        "            Whether the features are already standardized. By saying standardized, it means the\n",
        "            data is already transformed to lie in \"border\". It is recommanded that users do not \n",
        "            mannually input values for both \"border\" and \"standardize\", in which case the program\n",
        "            will automatically pre-process the dataset.        \n",
        "        criterion: 'gini'\n",
        "            Criterion for computing impurity. Currently only supports 'gini'.\n",
        "        min_split_weight: float\n",
        "            The minimal weight for a node to be further partitioned. If not provided, it will\n",
        "            be the value of parameter \"weight\".\n",
        "        min_leaf_weight: float\n",
        "            The minimal weight of lead nodes. If not provided, the program will set it to be 1.\n",
        "        tol: float\n",
        "            Tolerance for errors in comparison. Default is 10^(-5).\n",
        "        maximal_leaves:\n",
        "            Maximal number of leave nodes. If not provided, the program will run until no partition\n",
        "            can be further accepted.\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        This function does not directly return any variables. The built tree can be printed by calling\n",
        "        \"self.print()\". To predict new data with the built tree, refer to function \"predict\".        \n",
        "        '''\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "        n, d = np.shape(X)           ## n: number of samples; d: number of features\n",
        "        self.d = d\n",
        "        if border == None:\n",
        "            border = np.zeros((d,2))\n",
        "            border[:,1] = 1\n",
        "        if not standardize:\n",
        "            X = self.data_standardize(X)\n",
        "        if min_split_weight == None:\n",
        "            min_split_weight = weight+1\n",
        "        if min_leaf_weight == None:\n",
        "            min_leaf_weight = 1\n",
        "        if maximal_leaves == None:\n",
        "            maximal_leaves = np.floor(np.sqrt(n))\n",
        "        wn_all = len(Y) + (weight-1)*sum(Y)\n",
        "        self.wn = wn_all\n",
        "        self.wy = weight*sum(Y)\n",
        "        self.impu = self.Compute_Impu(self.wy, self.wn)\n",
        "        self.class_label = 1\n",
        "        self.sign_impu = self.Compute_SignImpu(self.wy, self.wn, self.class_label)\n",
        "        tree_impu = self.impu\n",
        "        tree_sign_impu = self.sign_impu\n",
        "\n",
        "        volume = np.prod(border[:,1] - border[:,0])\n",
        "        surface = 0\n",
        "        for j in range(d):\n",
        "            surface += 2 * volume / (border[j,1]-border[j,0])\n",
        "        sv_reg_min = self.sv_regular(surface, volume, d)\n",
        "        risk = tree_impu + pen * sv_reg_min\n",
        "        self.class_label = int(self.wy/self.wn>=0.5)\n",
        "        self.rec = border\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        node_que = collections.deque([self])   ## node_que is the queue that stores the nodes to operate, right side in and left side out\n",
        "        rec_que = collections.deque([border]) \n",
        "        label_que = collections.deque([1])        \n",
        "        reclst_leg = []\n",
        "        labellst_leg = []\n",
        "        feats_usage = np.zeros(d, dtype=bool)\n",
        "        n_operate_nodes = 1\n",
        "\n",
        "        while len(node_que) > 0 and n_operate_nodes < maximal_leaves:    ## Note surface, volume, tree_impu are attributes of a certain subtree (which contains root) rather than a node\n",
        "            n_operate_nodes += 1\n",
        "            node = node_que.popleft()\n",
        "            rec = rec_que.popleft()\n",
        "            reclst = list(rec_que)\n",
        "            reclst.extend(reclst_leg)\n",
        "            label = label_que.popleft()\n",
        "            labellst = list(label_que)\n",
        "            labellst.extend(labellst_leg)\n",
        "            ans = self.surface_funs(rec, label, reclst, labellst)    ## ans contains information about changes of surface after partitions\n",
        "            s_0, s_1 = ans[d]\n",
        "            if label == 1:\n",
        "                s_origin = s_1\n",
        "            else:\n",
        "                s_origin = s_0\n",
        "            volume0 = volume - label * np.prod(rec[:,1] - rec[:,0])  ## The quantities subtitled by 0 remain unchanged through the next for loop\n",
        "            # print(volume0, rec)\n",
        "            if volume0 < -tol:          ## a bug-checking procedure\n",
        "                pdb.set_trace()\n",
        "                print('Negative volume0: '+str(volume0))\n",
        "                raise Exception('Negative volume0: '+str(volume0))\n",
        "            surface0 = surface\n",
        "            tree_impu0 = tree_impu - node.impu * node.wn\n",
        "            tree_sign_impu0 = tree_sign_impu - node.sign_impu * node.wn/wn_all\n",
        "            \n",
        "            featureid = -1         ## featureid=-1 means no better partition is found\n",
        "            feats_reorder = np.append(np.flatnonzero(feats_usage), np.flatnonzero(1-feats_usage))\n",
        "            node_impu_selected = node.impu\n",
        "            S_faces = np.zeros(d)\n",
        "            for j in feats_reorder:\n",
        "                checkpoints, slope10, intercept10, S_faces[j] = ans[j]\n",
        "                loc = 0          ## loc is the largest index of checkpoints that are no greater than thre\n",
        "                wleft = 0\n",
        "                wyleft = 0\n",
        "                dat = np.core.records.fromarrays(np.array([node.X[:,j], node.Y]), names='feature, label')\n",
        "                dat = np.sort(dat, order='feature')\n",
        "                for sa in range(len(node.Y)-1):    ## sa is short for sample                        \n",
        "                    wyleft = wyleft + weight*dat[sa][1]\n",
        "                    wleft = wleft + 1 + (weight-1)*dat[sa][1]\n",
        "                    try:\n",
        "                        if wleft < min_leaf_weight or dat[sa][0]-rec[j,0] < tol:\n",
        "                            pass\n",
        "                        elif node.wn - wleft < min_leaf_weight or rec[j,1]-dat[sa+1][0]< tol:\n",
        "                            pass\n",
        "                    except:\n",
        "                        pdb.set_trace()\n",
        "                        print(dat[sa][0], dat[sa+1][0], rec[j,0], rec[j,1])\n",
        "                    if wleft < min_leaf_weight or dat[sa][0]-rec[j,0] < tol:\n",
        "                        continue\n",
        "                    elif node.wn - wleft < min_leaf_weight or rec[j,1]-dat[sa+1][0]< tol:\n",
        "                        break\n",
        "                    if (dat[sa+1][0] != dat[sa][0]):\n",
        "                        thre_new = (dat[sa+1][0]+dat[sa][0]) / 2\n",
        "                        node_impu_new = self.Compute_NodeImpu(wyleft, wleft, node.wy, node.wn)\n",
        "                        while loc < len(checkpoints)-1 and checkpoints[loc+1] <= thre_new:\n",
        "                            loc += 1\n",
        "                        tree_impu_new = node_impu_new * node.wn / wn_all + tree_impu0\n",
        "\n",
        "                        \n",
        "                        tree_sign_impu_new_lst = [tree_sign_impu0]*4\n",
        "                        surface_new_lst = [0,0,0,0]\n",
        "                        volume_new_lst = [0,0,0,0]\n",
        "                        risk_new_lst = [0,0,0,0]\n",
        "                        child_labels_lst = [[1,1], [0,0], [0,1], [1,0]]\n",
        "                        \n",
        "                        '''If both child nodes are labeled 1'''\n",
        "                        surface_new_lst[0] = surface0 + s_1 - s_origin\n",
        "                        volume_new_lst[0] = np.prod(rec[:,1] - rec[:,0]) + volume0\n",
        "                        tree_sign_impu_new_lst[0] = tree_sign_impu_new_lst[0] + node.wn / wn_all * self.Compute_SignNodeImpu(wyleft, wleft, node.wy, node.wn, [1,1])\n",
        "                        if volume_new_lst[0] <= 0 or surface_new_lst[0] <= 0:\n",
        "                            svr = sv_reg_min\n",
        "                        else:\n",
        "                            svr = self.sv_regular(surface_new_lst[0], volume_new_lst[0], d) \n",
        "                        risk_new_lst[0] = tree_sign_impu_new_lst[0] + pen*svr \n",
        "                        \n",
        "                        '''If both child nodes are labeled 0'''\n",
        "                        surface_new_lst[1] = surface0 + s_0 - s_origin\n",
        "                        volume_new_lst[1] = volume0\n",
        "                        tree_sign_impu_new_lst[1] = tree_sign_impu_new_lst[1] + node.wn / wn_all * self.Compute_SignNodeImpu(wyleft, wleft, node.wy, node.wn, [0,0])\n",
        "                        if volume_new_lst[1] <= 0 or surface_new_lst[1] <= 0:\n",
        "                            svr = sv_reg_min\n",
        "                        else:\n",
        "                            svr = self.sv_regular(surface_new_lst[1], volume_new_lst[1], d) \n",
        "                        risk_new_lst[1] = tree_sign_impu_new_lst[1] + pen*svr                    \n",
        "\n",
        "                        '''If left child is labeled 0 and right child is labeled 1'''\n",
        "                        surface_new_lst[2] = surface0 + s_0 + s_1 + 2*S_faces[j] - (intercept10[loc] + slope10[loc]*(thre_new-checkpoints[loc])) - s_origin\n",
        "                        volume_new_lst[2] = volume0 + np.prod(np.delete(rec[:,1],j)-np.delete(rec[:,0],j)) * (rec[j,1]-thre_new)\n",
        "                        tree_sign_impu_new_lst[2] = tree_sign_impu_new_lst[2] + node.wn / wn_all * self.Compute_SignNodeImpu(wyleft, wleft, node.wy, node.wn, [0,1])\n",
        "                        if volume_new_lst[2] <= 0 or surface_new_lst[2] <= 0:\n",
        "                            svr = sv_reg_min\n",
        "                        else:\n",
        "                            svr = self.sv_regular(surface_new_lst[2], volume_new_lst[2], d)\n",
        "                        risk_new_lst[2] = tree_sign_impu_new_lst[2] + pen*svr \n",
        "\n",
        "                        '''If left child is labeled 1 and right child is labeled 0'''\n",
        "                        surface_new_lst[3] = surface0 + intercept10[loc] + slope10[loc]*(thre_new-checkpoints[loc]) - s_origin\n",
        "                        volume_new_lst[3] = volume0 + np.prod(np.delete(rec[:,1],j)-np.delete(rec[:,0],j)) * (thre_new-rec[j,0])\n",
        "                        tree_sign_impu_new_lst[3] = tree_sign_impu_new_lst[3] + node.wn / wn_all * self.Compute_SignNodeImpu(wyleft, wleft, node.wy, node.wn, [1,0])\n",
        "                        if volume_new_lst[3] <= 0 or surface_new_lst[3] <= 0:\n",
        "                            svr = sv_reg_min\n",
        "                        else:\n",
        "                            svr = self.sv_regular(surface_new_lst[3], volume_new_lst[3], d)\n",
        "                        risk_new_lst[3] = tree_sign_impu_new_lst[3] + pen*svr    \n",
        "                        \n",
        "                        argmin = np.argmin(risk_new_lst)\n",
        "                        \n",
        "                        if np.min(surface_new_lst) < - tol:\n",
        "                            print('reclst:', reclst)\n",
        "                            print('rec:', rec, 'len(reslst):', len(reclst))                            \n",
        "                            print('slope10:', slope10, 'intercept10:', intercept10)\n",
        "                            print('Negative surface: '+str(np.min(surface_new_lst))+'  pen: '+str(pen)+'  type: '+str(np.argmin(surface_new_lst)))\n",
        "                            print('volume0:', volume0, 'surface0:', surface0)\n",
        "                            print('featureid_now:', j, 'thre_now:', thre_new)\n",
        "                            \n",
        "                            pdb.set_trace()\n",
        "                            raise Exception('Negative surface: '+str(np.min(surface_new_lst))+'  pen:'+str(pen))\n",
        "                        if np.min(tree_sign_impu_new_lst) < - tol:\n",
        "                            print('Negative tree signed impurity: '+str(np.min(tree_sign_impu_new_lst)))\n",
        "\n",
        "                        if risk_new_lst[argmin] < risk:                           \n",
        "                            thre = thre_new\n",
        "                            featureid = j\n",
        "                            child_labels = child_labels_lst[argmin]\n",
        "                            surface = surface_new_lst[argmin]\n",
        "                            volume = volume_new_lst[argmin]\n",
        "                            tree_impu = tree_impu_new   \n",
        "                            tree_sign_impu = tree_sign_impu_new_lst[argmin]\n",
        "                            risk = risk_new_lst[argmin]\n",
        "                            if risk < -tol:\n",
        "                                print('Negative risk: '+str(risk)+'  pen:'+str(pen))\n",
        "                                print('signed impu: '+str(tree_sign_impu))\n",
        "                                print('volume: '+str(volume))\n",
        "                                print('surface: '+str(surface))\n",
        "                                pdb.set_trace()\n",
        "                                raise Exception('Negative risk: '+str(risk)+'  pen:'+str(pen))\n",
        "\n",
        "            if featureid >= 0:                     ## i.e., a better partition is found\n",
        "                node.leaf = False\n",
        "                feats_usage[featureid] = True\n",
        "                node.split = [featureid, thre]\n",
        "                node.left = tree()\n",
        "                node.left.standardize_para = node.standardize_para\n",
        "                leftind = np.flatnonzero(node.X[:,featureid]<=thre)\n",
        "                node.left.X = node.X[leftind,]\n",
        "                node.left.Y = node.Y[leftind]\n",
        "                node.left.wn = len(node.left.Y) + (weight-1) * sum(node.left.Y)\n",
        "                node.left.wy = weight * sum(node.left.Y)\n",
        "                node.left.impu = self.Compute_Impu(node.left.wy, node.left.wn)\n",
        "                node.left.class_label = child_labels[0]\n",
        "                node.left.sign_impu = self.Compute_SignImpu(node.left.wy, node.left.wn, node.left.class_label)\n",
        "                node.left.rec = rec.copy()\n",
        "                node.left.rec[featureid,1] = thre\n",
        "                if node.left.wy == 0 or node.left.wy == node.left.wn or node.left.wn < min_split_weight:\n",
        "                    node.left.leaf = True\n",
        "                    if node.left.class_label == 1:\n",
        "                        reclst_leg.append(node.left.rec)\n",
        "                        labellst_leg.append(1)\n",
        "                else:\n",
        "                    node_que.append(node.left)\n",
        "                    rec_que.append(node.left.rec)\n",
        "                    label_que.append(node.left.class_label)\n",
        "                node.right = tree()\n",
        "                node.right.standardize_para = node.standardize_para\n",
        "                rightind = np.flatnonzero(node.X[:,featureid]>thre)\n",
        "                node.right.X = node.X[rightind,]\n",
        "                node.right.Y = node.Y[rightind]\n",
        "                node.right.wn = len(node.right.Y) + (weight-1) * sum(node.right.Y)\n",
        "                node.right.wy = weight * sum(node.right.Y)\n",
        "                node.right.impu = self.Compute_Impu(node.right.wy, node.right.wn)\n",
        "                node.right.class_label = child_labels[1]\n",
        "                node.right.sign_impu = self.Compute_SignImpu(node.right.wy, node.right.wn, node.right.class_label)\n",
        "                node.right.rec = rec.copy()\n",
        "                node.right.rec[featureid,0] = thre\n",
        "                node.right.rec[featureid,0] = thre\n",
        "                if node.right.wy == 0 or node.right.wy == node.right.wn or node.right.wn < min_split_weight:\n",
        "                    node.right.leaf = True\n",
        "                    if node.right.class_label == 1:\n",
        "                        reclst_leg.append(node.right.rec)\n",
        "                        labellst_leg.append(1)\n",
        "                else:\n",
        "                    node_que.append(node.right)\n",
        "                    rec_que.append(node.right.rec)\n",
        "                    label_que.append(node.right.class_label)\n",
        "            else:\n",
        "                if node.class_label == 1:\n",
        "                    reclst_leg.append(node.rec)\n",
        "                    labellst_leg.append(1)\n",
        "                    \n",
        "        self.feats_usage = feats_usage\n",
        "        return\n",
        "\n",
        "\n",
        "    def data_standardize(self, X):\n",
        "        ''' A function of class tree which linearly transfers feature matrix to [0,1]^d. '''\n",
        "        n, d = np.shape(X) \n",
        "        border = np.zeros((d,2))\n",
        "        for j in range(d):\n",
        "            feat_min = min(X[:,j])\n",
        "            feat_max = max(X[:,j])\n",
        "            if feat_max == feat_min:\n",
        "                raise Exception('feature '+str(j)+' has only one value')\n",
        "            border_dist = (feat_max-feat_min)/(n-1)\n",
        "            border[j,:] = [feat_min-border_dist, feat_max+border_dist]    \n",
        "        shifts = - border[:,0]\n",
        "        multipliers = np.diag(1/(border[:,1]-border[:,0]))\n",
        "        self.standardize_para = (shifts, multipliers)\n",
        "        return np.matmul(X + np.reshape(shifts, (1,d)), multipliers)  \n",
        "                    \n",
        "    @staticmethod\n",
        "    def sv_regular(surface, volume, d):\n",
        "        ''' Compute surface-to-volume regularization. '''\n",
        "        return surface/volume\n",
        "    \n",
        "    @staticmethod\n",
        "    def Compute_Impu(wy, w, criterion='gini'):\n",
        "        ''' Compute impurity of a node. '''\n",
        "        return 1 - (wy/w)**2 - ((w-wy)/w)**2 \n",
        "        \n",
        "    @staticmethod\n",
        "    def Compute_SignImpu(wy, w, label, criterion='gini'):\n",
        "        ''' Compute signed impurity of a node. '''\n",
        "        if int(wy/w>=0.5) == label:\n",
        "            return 1 - (wy/w)**2 - ((w-wy)/w)**2\n",
        "        else:\n",
        "            return (wy/w)**2 + ((w-wy)/w)**2\n",
        "        \n",
        "    @staticmethod\n",
        "    def Compute_NodeImpu(wyleft, wleft, wy, w, criterion='gini'):\n",
        "        ''' Compute impurity of a node after a partition. '''\n",
        "        return 1 - ((wyleft/wleft)**2 + ((wleft-wyleft)/wleft)**2)*wleft/w \\\n",
        "                - (((wy-wyleft)/(w-wleft))**2 + ((w-wleft-wy+wyleft)/(w-wleft))**2)*(w-wleft)/w \n",
        "    \n",
        "    @staticmethod\n",
        "    def Compute_SignNodeImpu(wyleft, wleft, wy, w, child_labels, criterion='gini'):\n",
        "        ''' Compute signed impurity of a node after a partition. '''\n",
        "        impu_left = 1 - (wyleft/wleft)**2 - ((wleft-wyleft)/wleft)**2\n",
        "        impu_right = 1 - ((wy-wyleft)/(w-wleft))**2 - ((w-wleft-wy+wyleft)/(w-wleft))**2\n",
        "        if int(wyleft/wleft>=0.5) == child_labels[0]:\n",
        "            impu_left_sign = impu_left\n",
        "        else:\n",
        "            impu_left_sign = 1 - impu_left\n",
        "        if int((wy-wyleft)/(w-wleft)>=0.5) == child_labels[1]:\n",
        "            impu_right_sign = impu_right\n",
        "        else:\n",
        "            impu_right_sign = 1 - impu_right\n",
        "        return impu_left_sign*wleft/w + impu_right_sign*(w-wleft)/w  \n",
        "    \n",
        "                \n",
        "    def predict(self, X):    \n",
        "        '''\n",
        "        This function return predict class labels for a new data using the tree \"self\".\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: ndarray\n",
        "            Feature matrix of new data. Must has the same number of features as \n",
        "            the training data.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        var: ndarray\n",
        "            One-dimensional array contains the predicted class labels of new data.\n",
        "        '''\n",
        "        X = np.array(X)\n",
        "        d = np.shape(X)[1]\n",
        "        if not self.standardize_para == None:\n",
        "            shifts, multipliers = self.standardize_para\n",
        "            X = np.matmul(X + np.reshape(shifts, (1,d)), multipliers)\n",
        "        return self.localpredict(X)\n",
        "    \n",
        "    def localpredict(self, X): \n",
        "        ''' This recursive functions is called by function \"predict\" to complete \n",
        "        its taks of predicting class labels. '''\n",
        "        if self.leaf:\n",
        "            return self.class_label * np.ones(np.shape(X)[0],dtype=int)\n",
        "        else:\n",
        "            Y = np.zeros(np.shape(X)[0],dtype=int)\n",
        "            featureid, thre = self.split\n",
        "            featureid = np.int_(featureid)\n",
        "            leftind = np.flatnonzero(X[:,featureid]<=thre)\n",
        "            Y[leftind] = self.left.localpredict(X[leftind,:])\n",
        "            rightind = np.flatnonzero(X[:,featureid]>thre)\n",
        "            Y[rightind] = self.right.localpredict(X[rightind,:])\n",
        "            return Y\n",
        "                \n",
        "    def print(self, init=True, print_weight=False, print_impu=False):\n",
        "        '''\n",
        "        This function print a tree.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        init: boolean\n",
        "            Whether the printing is started from root node. If not called by the \n",
        "            the function \"print\" itself, it should always set to be True. Default \n",
        "            value is True.\n",
        "        print_weight: boolean\n",
        "            Whether to print the weight of training samples in each node. Default\n",
        "            is False.\n",
        "        print_impu: boolean\n",
        "            Whether to print the impurity of training samples in each node. Default\n",
        "            is False.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        This function returns nothing.\n",
        "        \n",
        "        Outputs\n",
        "        -------\n",
        "        This function will print all the nodes of the tree in a depth-first order.\n",
        "        '''\n",
        "        if init:\n",
        "            self.codename = 'root'\n",
        "        if self.leaf:\n",
        "            print(self.codename+':', self.class_label)\n",
        "            if print_weight:\n",
        "                print('class 1 weight, total weight:', self.wy, self.wn)\n",
        "            if print_impu:\n",
        "                print('impurity:', self.impu)                \n",
        "        else:\n",
        "            print(self.codename+':', 'feature '+str(self.split[0])+' <= '+str(self.split[1]))\n",
        "            if print_weight:\n",
        "                print('class 1 weight and total weight:', self.wy, self.wn)\n",
        "            if print_impu:\n",
        "                print('impurity, impurity_decr:', self.impu, self.impu_decr, self.tot_impudecr, self.alpha)\n",
        "            self.left.codename = self.codename + '.left'\n",
        "            self.left.print(False, print_weight, print_impu)\n",
        "            self.right.codename = self.codename + '.right'\n",
        "            self.right.print(False, print_weight, print_impu)\n",
        "         \n",
        "            \n",
        "    def copy(self):\n",
        "        ''' Copy the current tree represented by \"self\". '''\n",
        "        copytr = tree()\n",
        "        copytr.leaf = self.leaf\n",
        "        copytr.impu = self.impu\n",
        "        copytr.wn = self.wn\n",
        "        copytr.wy = self.wy\n",
        "        if self.leaf:\n",
        "            copytr.class_label = self.class_label\n",
        "        else:\n",
        "            copytr.split = self.split\n",
        "            copytr.impu_decr = self.impu_decr\n",
        "            copytr.left = self.left.copy()\n",
        "            copytr.right = self.right.copy()\n",
        "        return copytr"
      ],
      "metadata": {
        "id": "iqwFcLaVqetb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the data loading and pre-processing cell\n",
        "da0 = pd.read_csv('/content/Indian Liver Patient Dataset (ILPD).csv',header=None) \n",
        "da0[1] = LabelEncoder().fit_transform(da0[1])\n",
        "da = da0.values\n",
        "n, d = np.shape(da)\n",
        "d = d-1\n",
        "Xall = da[:,0:d]\n",
        "n1_ind = np.flatnonzero(da[:,d]==2)\n",
        "Yall = np.zeros(n,dtype=int)\n",
        "Yall[n1_ind] = 1\n",
        "times = int((n-len(n1_ind))/len(n1_ind)) - 1"
      ],
      "metadata": {
        "id": "g80dWqCpDZ8T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and Test splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xall, Yall, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "k7dWMX_EDyn0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#penality parameter list\n",
        "n1 = len(np.flatnonzero(Yall))\n",
        "n0 = n - n1\n",
        "train_ratio = 0.8\n",
        "n1train = np.int_(n1*train_ratio)\n",
        "n0train = np.int_(n0*train_ratio)\n",
        "pen_lst = np.array([0, 1, 1.4, 2, 2.8, 4, 5.7, 8, 11, 16, 22, 32, 44, 64, 89, 128, 179, 256, 358, 512, 716, 1024]) * 10**(-3) * (n0train+n1train)**(-1/3)"
      ],
      "metadata": {
        "id": "9DxqIshmD0wi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_sample(X, y):\n",
        "    n_samples = X.shape[0]\n",
        "    idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    return X[idxs], y[idxs]\n",
        "def most_common_label(y):\n",
        "    counter = Counter(y)\n",
        "    most_common = counter.most_common(1)[0][0]\n",
        "    return most_common\n",
        "class RandomForest:\n",
        "    \n",
        "    def __init__(self, n_trees=40, min_samples_split=2,\n",
        "                 max_depth=100, n_feats=None, weight=1):\n",
        "        self.n_trees = n_trees\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.n_feats = n_feats\n",
        "        self.weight = weight\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        for i in range(self.n_trees):\n",
        "            tr_svr = tree()\n",
        "            X_samp, y_samp = bootstrap_sample(X, y)\n",
        "            F_lst = np.zeros(len(pen_lst))\n",
        "            for j in range(len(pen_lst)):\n",
        "                TP=0\n",
        "                FP=0\n",
        "                tr_svr = tree()\n",
        "                tr_svr.fit_sv(X_samp, y_samp, pen_lst[j], weight=self.weight, maximal_leaves=2*np.sqrt(n*2/3))\n",
        "                Y_pred_temp = tr_svr.predict(X_samp)\n",
        "                TP += np.sum(Y_pred_temp[np.flatnonzero(y_samp)])\n",
        "                FP += np.sum(Y_pred_temp[np.flatnonzero(y_samp==0)])\n",
        "            if TP > 0:\n",
        "                tpr = TP / n1train\n",
        "                precision = TP / (TP+FP)\n",
        "                F_lst[j] = 2*tpr*precision / (tpr+precision)\n",
        "            para_id = np.argmax(F_lst)\n",
        "            tr_svr = tree()\n",
        "            tr_svr.fit_sv(X_samp, y_samp, pen_lst[para_id], weight=self.weight, maximal_leaves=2*np.sqrt(n*2/3))\n",
        "            self.trees.append(tr_svr)\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
        "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
        "        y_pred = [most_common_label(tree_pred) for tree_pred in tree_preds]\n",
        "        return np.array(y_pred)"
      ],
      "metadata": {
        "id": "U3swKkmWD3QT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForest(weight=times+1)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)"
      ],
      "metadata": {
        "id": "0h_RFZqsD5iM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test, preds))\n",
        "print(roc_auc_score(y_test, preds))\n",
        "print(f1_score(y_test, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuMWhYNiD7dr",
        "outputId": "00fa80b0-ae7b-402a-d100-5637afd947da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7094017094017094\n",
            "0.6730769230769231\n",
            "0.5641025641025641\n"
          ]
        }
      ]
    }
  ]
}